{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Poem_generator.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/zahraDehghanian97/Poetry_Generator/blob/master/Word_Poem_generator.ipynb",
      "authorship_tag": "ABX9TyMmBRA4lgbqdl2pYm5h2JEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/Poetry_Generator/blob/master/Word_Poem_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "from nltk.metrics import accuracy ,ConfusionMatrix \n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erM3Mb3nuFAR"
      },
      "source": [
        "seqLength = 20\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 100\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxSaPGaqHfMV"
      },
      "source": [
        "# make data ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNCS1WcxmTMB"
      },
      "source": [
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/my_shahname_represntation.txt\"\n",
        "with open(filepath, \"rb\") as f:\n",
        "    corpus , test = pickle.load(f)\n",
        "corpus = corpus.replace(\"\\t\",\" \\t \").replace(\"\\n\", \" \\n \")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11TwQxzmVBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94af29f2-79b7-4eaf-856f-614bf365668f"
      },
      "source": [
        "corpusList = [w for w in corpus.split(' ')] \n",
        "corpus_words = [i for i in corpusList if i]\n",
        "map(str.strip, corpus_words)\n",
        "vocab = sorted(set(corpus_words))\n",
        "print(len(corpus_words))\n",
        "vocab_size = len(vocab)\n",
        "word2idx = {u: i for i, u in enumerate(vocab)}\n",
        "idx2words = np.array(vocab)\n",
        "word_as_int = np.array([word2idx[c] for c in corpus_words])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "606052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLvTwoNhep0"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "# examples_per_epoch = len(corpus_words)//(seqLength + 1)\n",
        "wordDataset = tf.data.Dataset.from_tensor_slices(word_as_int)\n",
        "sequencesOfWords = wordDataset.batch(seqLength + 1, drop_remainder=True)\n",
        "dataset = sequencesOfWords.map(split_input_target)\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLOB0rSQHbe7"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47qIyVAcHdak"
      },
      "source": [
        "def create_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]))\n",
        "  model.add(tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(tf.keras.layers.Dense(vocab_size))\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73V4sMfZLT1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d00f2e-d929-4584-b022-9c8754ab13a5"
      },
      "source": [
        "lstm_model = create_model_lstm(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
        "lstm_model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "history = lstm_model.fit(dataset, epochs=50)\n",
        "main_lstm_model = create_model_lstm(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=1)\n",
        "main_lstm_model.set_weights(lstm_model.get_weights())\n",
        "# main_lstm_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/word_lstm.h5')\n",
        "main_lstm_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "450/450 [==============================] - 64s 135ms/step - loss: 6.9648 - accuracy: 0.0743\n",
            "Epoch 2/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 6.2403 - accuracy: 0.1036\n",
            "Epoch 3/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 5.4921 - accuracy: 0.1513\n",
            "Epoch 4/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 5.1126 - accuracy: 0.2139\n",
            "Epoch 5/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 4.9087 - accuracy: 0.2264\n",
            "Epoch 6/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 4.7511 - accuracy: 0.2362\n",
            "Epoch 7/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 4.6100 - accuracy: 0.2447\n",
            "Epoch 8/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 4.4782 - accuracy: 0.2521\n",
            "Epoch 9/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 4.3420 - accuracy: 0.2596\n",
            "Epoch 10/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 4.2134 - accuracy: 0.2673\n",
            "Epoch 11/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 4.0972 - accuracy: 0.2752\n",
            "Epoch 12/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.9854 - accuracy: 0.2840\n",
            "Epoch 13/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.8784 - accuracy: 0.2944\n",
            "Epoch 14/50\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 3.7779 - accuracy: 0.3040\n",
            "Epoch 15/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 3.6888 - accuracy: 0.3141\n",
            "Epoch 16/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.6039 - accuracy: 0.3234\n",
            "Epoch 17/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.5196 - accuracy: 0.3335\n",
            "Epoch 18/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.4436 - accuracy: 0.3421\n",
            "Epoch 19/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.3691 - accuracy: 0.3516\n",
            "Epoch 20/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.2978 - accuracy: 0.3608\n",
            "Epoch 21/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.2284 - accuracy: 0.3701\n",
            "Epoch 22/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 3.1553 - accuracy: 0.3800\n",
            "Epoch 23/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 3.0884 - accuracy: 0.3905\n",
            "Epoch 24/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 3.0249 - accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.9651 - accuracy: 0.4095\n",
            "Epoch 26/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.9037 - accuracy: 0.4183\n",
            "Epoch 27/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.8497 - accuracy: 0.4274\n",
            "Epoch 28/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.7928 - accuracy: 0.4370\n",
            "Epoch 29/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.7378 - accuracy: 0.4460\n",
            "Epoch 30/50\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 2.6866 - accuracy: 0.4547\n",
            "Epoch 31/50\n",
            "450/450 [==============================] - 62s 137ms/step - loss: 2.6325 - accuracy: 0.4641\n",
            "Epoch 32/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.5801 - accuracy: 0.4730\n",
            "Epoch 33/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.5276 - accuracy: 0.4833\n",
            "Epoch 34/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.4785 - accuracy: 0.4922\n",
            "Epoch 35/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.4304 - accuracy: 0.5008\n",
            "Epoch 36/50\n",
            "450/450 [==============================] - 62s 137ms/step - loss: 2.3817 - accuracy: 0.5099\n",
            "Epoch 37/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.3363 - accuracy: 0.5186\n",
            "Epoch 38/50\n",
            "450/450 [==============================] - 60s 134ms/step - loss: 2.2904 - accuracy: 0.5272\n",
            "Epoch 39/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.2434 - accuracy: 0.5368\n",
            "Epoch 40/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.2050 - accuracy: 0.5443\n",
            "Epoch 41/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.1616 - accuracy: 0.5526\n",
            "Epoch 42/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 2.1219 - accuracy: 0.5609\n",
            "Epoch 43/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.0772 - accuracy: 0.5700\n",
            "Epoch 44/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.0380 - accuracy: 0.5782\n",
            "Epoch 45/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 2.0037 - accuracy: 0.5855\n",
            "Epoch 46/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 1.9641 - accuracy: 0.5935\n",
            "Epoch 47/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 1.9289 - accuracy: 0.6015\n",
            "Epoch 48/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 1.8939 - accuracy: 0.6089\n",
            "Epoch 49/50\n",
            "450/450 [==============================] - 61s 135ms/step - loss: 1.8619 - accuracy: 0.6157\n",
            "Epoch 50/50\n",
            "450/450 [==============================] - 61s 136ms/step - loss: 1.8301 - accuracy: 0.6220\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (1, None, 256)            4864512   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 19002)          19477050  \n",
            "=================================================================\n",
            "Total params: 37,981,242\n",
            "Trainable params: 37,981,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL4gEU440DyQ"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 200\n",
        "  start_string_list =[]\n",
        "  for w in start_string.split(' '):\n",
        "    if w in word2idx :\n",
        "      start_string_list.append(w)\n",
        "  input_eval = [word2idx[s] for s in start_string_list]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(idx2words[predicted_id])\n",
        "  return (start_string + ' '.join(text_generated))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtcL1MWoI8zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f979f24-c2e9-4a27-bb41-9936c1959bfd"
      },
      "source": [
        "print(generate_text(main_lstm_model, start_string=u\"چنین گفت رستم به اسفندیار\"))\n",
        "main_lstm_model.save(\"/content/drive/MyDrive/Colab Notebooks/word_lstm.h5\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "چنین گفت رستم به اسفندیارپیش اندرون \t یکی خوب چیزی ندارد شتاب \n",
            " ز من خواستم زور دست \n",
            " که ما را بدی پاک ویران که در گنج دیگر شنید \n",
            " به سی و گرازان بر اسپ آورید \t به گرد اندرش آبهای شده \t نبودش بهی شیر را آفرین \n",
            " گزین کرد صندوق بر سنگ روی \t کمان دل و زخم بربط بدند \n",
            " دلیران برو چاک زد تاختن \t به شنگل بفرمود کان سر سرکشان \n",
            " چو بشنید سیندخت بر زال سام \t نیایش کنان برگفتند راه \n",
            " چو دیدند پیران به گشتاسپ گفت \t که گفتار او باب دل خسته شد \n",
            " دگر آنک دیدم ز ایران کنون \t سزد گر به رزم اندرون نیست باک \n",
            " چو اغریرث پرهنر شهریار \t درختی همی گشت بر چرخ ماه \n",
            " سر اندریمان به خاک آورید \t دل جنگجویان سر اندر مبند \n",
            " نخست آفرین کرد بر کردگار \t و بخشایشست \t برافروخت چون شیر فرمانروا \n",
            " سه هر کس که گفتی برآرد ز درد \t تن آسانی ما نگردد کهن \n",
            " یکی بنده‌ام بد بخنجر همه \t شده روز ایران به مازندران \n",
            " بدین است کردار پیل و جوان \t ز خویش و ز لشکر بباید بدر \n",
            " بدان ای یکی نو\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG9bckSb7ESO"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMPDnUA87GfX",
        "outputId": "c3bbb16d-6655-422c-9e59-71661fa61052"
      },
      "source": [
        "BLEU_scores = []\n",
        "accuracy_scores = []\n",
        "poem = test[0]\n",
        "start = poem[:25]\n",
        "generated_poem = generate_text(main_lstm_model, start_string=start)\n",
        "BLEU_scores.append(sentence_bleu(poem, generated_poem))\n",
        "len_min = min(len(poem),len(generated_poem))\n",
        "accuracy_scores.append(accuracy(poem[:len_min], generated_poem[:len_min]))\n",
        "print(\"-----------------------\")\n",
        "print(\"start sentence : \",start)\n",
        "print(generated_poem)\n",
        "print(\"BLEU score = \",BLEU_scores[-1])\n",
        "print(\"Accuracy score = \",accuracy_scores[-1])\n",
        "print(\"Confusion matrix =\")\n",
        "print(ConfusionMatrix(poem[:len_min], generated_poem[:len_min]))\n",
        "\n",
        "counter = 0\n",
        "for poem in test :\n",
        "  counter+=1\n",
        "  start = poem[:25]\n",
        "  generated_poem = generate_text(main_lstm_model, start_string=start)\n",
        "  BLEU_scores.append(sentence_bleu(poem, generated_poem))\n",
        "  len_min = min(len(poem),len(generated_poem))\n",
        "  accuracy_scores.append(accuracy(poem[:len_min], generated_poem[:len_min]))\n",
        "  print(\"-----------------------\")\n",
        "  print(\"sentence number : \",counter)\n",
        "  print(\"BLEU score = \",BLEU_scores[-1])\n",
        "  print(\"Accuracy score = \",accuracy_scores[-1])\n",
        "\n",
        "print(\"<<------------final report----------->>\")\n",
        "print(\"number of test set = \",len(test))\n",
        "print(\"mean BLEU score = \",np.mean(BLEU_scores))\n",
        "print(\"mean Accuracy score = \",np.mean(accuracy_scores))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "start sentence :  چو لشکر شد از خواسته بی‌ن\n",
            "چو لشکر شد از خواسته بی‌نخواندمش \t درم را بریزی به درویش بود \n",
            " وگر دیر بودش پلنگ \n",
            " برهنه شود ژنده او بر زمین \t همی بفگند بر سرش آفتاب \n",
            " شب تیره در درد چندان بدی \t چو ابر سیاه \t همی بود لرزان نیابد جواز \n",
            " بباید کشیدن گمان از کسی کو بدانش سزد \n",
            " تو دانی من این تخت را بر خورم \t بدرد کسی زان توانگر چراست \n",
            " بدو گفت نزدیک من بیش کیست \t اگر تاج یابد هنر داد و خوار \n",
            " نژند آیدم \t نه از تیغ رنگ رخش ناپدید \n",
            " فرود آمد از دشت نیزه‌وران \t به لشکر به دشت اندر آمد سترگ \n",
            " همی خواست تا شب گذشته سه پاس \n",
            " یکی بخت صد دیگر آتش پر از خون و روی زرد برسان نیل \n",
            " چه مردی بدو پهلوان خواندند \t زبرجد ز کافور وز مشک شد ناپدید \n",
            " سراپردهٔ دیبهٔ هفت‌رنگ \t بپوشید در بیشه رخسار او \n",
            " به کشتی کسی تا نگردد تهی \t چو شد سال بر کشته از دست او \n",
            " برو پیش بردند ایرانیان \t چه بر تنش گیتی چه جویی همی \n",
            " شما هم کنون از چه گوید سخن \t بجز تو ران رنج افراسیاب \n",
            " ازو برده افگنده بیکار\n",
            "BLEU score =  0.43803861848327813\n",
            "Accuracy score =  0.0997624703087886\n",
            "Confusion matrix =\n",
            "  |  \t  \n",
            "     آ  ا  ب  ت  ج  ح  خ  د  ذ  ر  ز  س  ش  ص  ع  غ  ف  ق  ل  م  ن  ه  و  ٔ  پ  چ  ژ  ک  گ  ی  ‌ |\n",
            "--+-------------------------------------------------------------------------------------------------------+\n",
            "\t | <.> 1  5  .  .  .  .  .  .  .  .  .  2  .  .  1  .  .  .  .  .  .  .  2  .  2  .  1  .  .  1  1  1  . |\n",
            "\n",
            " |  . <.> 2  .  .  2  1  1  .  1  3  .  .  1  .  .  .  .  .  .  .  .  1  .  2  2  .  .  .  .  .  .  .  . |\n",
            "  |  2  .<43> . 11 11 11  2  .  1  8  .  7  2  2  4  .  .  .  2  .  1  4  5  8  4  .  3  .  .  2  4 11  2 |\n",
            "آ |  .  .  . <.> 1  .  1  .  .  3  2  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  . |\n",
            "ا |  1  1 15  . <5> 3  2  .  .  .  8  .  6  3  2  5  .  .  .  1  .  1  2  4  5  5  .  1  .  .  .  3  9  . |\n",
            "ب |  2  1 10  .  4 <2> .  .  .  .  3  .  4  2  2  1  .  .  .  2  .  .  .  3  .  1  .  .  1  .  1  .  2  . |\n",
            "ت |  .  .  7  1  1  1 <2> .  .  .  1  .  .  .  1  .  .  .  .  .  .  .  .  2  .  .  .  .  1  .  1  1  .  . |\n",
            "ج |  1  .  2  .  1  .  . <.> .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  3  .  .  .  .  1  .  .  .  .  . |\n",
            "ح |  .  .  .  .  .  .  .  . <.> 1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  1  .  .  . |\n",
            "خ |  .  .  6  2  .  .  1  .  . <1> 2  .  .  1  .  1  .  .  .  .  .  .  .  1  .  1  .  .  .  .  .  .  1  . |\n",
            "د |  1  1 10  1  3  2  2  .  .  1 <5> 1  4  2  1  2  .  .  1  .  .  .  1  2  2  4  1  1  .  .  1  .  2  . |\n",
            "ذ |  .  .  .  .  .  .  .  .  .  .  . <.> 1  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  . |\n",
            "ر |  .  4 17  .  4  2  4  .  .  .  7  . <3> .  2  2  .  .  .  .  .  .  2  5  1  3  .  2  1  .  .  2  2  . |\n",
            "ز |  1  .  6  .  2  1  .  .  .  1  .  .  2 <1> .  .  .  .  .  .  .  .  .  1  1  2  .  .  1  .  1  .  .  . |\n",
            "س |  .  .  7  .  3  2  1  .  .  .  .  .  2  2 <1> .  .  .  .  .  .  .  1  .  1  2  .  .  .  .  1  .  1  . |\n",
            "ش |  .  2  5  .  .  .  1  .  .  .  1  .  3  1  1 <3> .  .  .  1  .  .  1  2  1  .  .  .  .  .  .  .  .  . |\n",
            "ص |  .  .  .  .  .  .  .  .  .  .  1  .  .  1  .  . <.> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
            "ع |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <.> .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  . |\n",
            "غ |  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  . <.> .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
            "ف |  .  .  1  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  . <.> .  .  .  .  .  .  .  .  1  .  .  .  2  . |\n",
            "ق |  .  .  1  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  . <.> .  .  1  .  .  .  .  .  .  .  .  .  . |\n",
            "ل |  .  .  2  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  1  .  .  . |\n",
            "م |  1  2 13  .  1  4  1  1  .  .  2  .  1  1  .  .  .  .  .  .  .  . <.> 1  .  1  .  .  1  .  .  .  1  . |\n",
            "ن |  2  . 13  .  5  2  1  1  .  1  4  .  5  .  1  1  1  .  .  2  .  .  1 <4> 1  1  .  .  .  .  .  .  4  . |\n",
            "ه |  1  . 12  .  8  5  .  1  .  .  5  .  1  .  1  .  .  .  .  .  .  1  1  1 <2> 1  .  .  .  .  .  1  4  . |\n",
            "و |  .  1  5  .  3  1  .  .  .  1  3  .  5  2  3  3  .  .  .  .  .  1  3  5  2 <5> .  .  .  1  3  3  3  . |\n",
            "ٔ |  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  . <.> .  .  .  1  .  .  . |\n",
            "پ |  .  .  1  .  2  .  .  .  .  .  .  .  3  .  1  .  .  .  .  .  .  .  .  .  1  2  . <.> .  .  .  .  1  . |\n",
            "چ |  .  .  1  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <1> 1  .  .  .  . |\n",
            "ژ |  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <.> .  .  .  . |\n",
            "ک |  .  1  3  1  1  .  .  .  .  .  3  .  3  .  .  2  .  .  .  .  .  .  .  3  1  .  .  .  .  . <1> .  1  . |\n",
            "گ |  .  1  .  .  1  1  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  .  1  1  .  .  .  .  . <.> 1  . |\n",
            "ی |  1  1 16  .  2  2  1  .  .  1  2  .  2  2  1  2  .  .  .  .  .  2  .  4  3  2  .  1  1  .  1  1 <3> . |\n",
            "‌ |  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  1 <1>|\n",
            "--+-------------------------------------------------------------------------------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "-----------------------\n",
            "sentence number :  1\n",
            "BLEU score =  0.4325487967002789\n",
            "Accuracy score =  0.11318553092182031\n",
            "-----------------------\n",
            "sentence number :  2\n",
            "BLEU score =  0.4189456885152406\n",
            "Accuracy score =  0.10336538461538461\n",
            "-----------------------\n",
            "sentence number :  3\n",
            "BLEU score =  0.43964428022850555\n",
            "Accuracy score =  0.11207970112079702\n",
            "-----------------------\n",
            "sentence number :  4\n",
            "BLEU score =  0.430668002296931\n",
            "Accuracy score =  0.12930011862396204\n",
            "-----------------------\n",
            "sentence number :  5\n",
            "BLEU score =  0.44681986341279845\n",
            "Accuracy score =  0.10785463071512309\n",
            "-----------------------\n",
            "sentence number :  6\n",
            "BLEU score =  0.43242270754632145\n",
            "Accuracy score =  0.10839160839160839\n",
            "-----------------------\n",
            "sentence number :  7\n",
            "BLEU score =  0.4413023019063527\n",
            "Accuracy score =  0.10872313527180784\n",
            "-----------------------\n",
            "sentence number :  8\n",
            "BLEU score =  0.43539267254561004\n",
            "Accuracy score =  0.10161090458488228\n",
            "-----------------------\n",
            "sentence number :  9\n",
            "BLEU score =  0.4256496200321842\n",
            "Accuracy score =  0.09964830011723329\n",
            "-----------------------\n",
            "sentence number :  10\n",
            "BLEU score =  0.4231439379298937\n",
            "Accuracy score =  0.10357583230579531\n",
            "-----------------------\n",
            "sentence number :  11\n",
            "BLEU score =  0.4329281703700091\n",
            "Accuracy score =  0.11475409836065574\n",
            "-----------------------\n",
            "sentence number :  12\n",
            "BLEU score =  0.42393021063819475\n",
            "Accuracy score =  0.10677083333333333\n",
            "-----------------------\n",
            "sentence number :  13\n",
            "BLEU score =  0.4256496200321842\n",
            "Accuracy score =  0.12895662368112543\n",
            "-----------------------\n",
            "sentence number :  14\n",
            "BLEU score =  0.4328670093639808\n",
            "Accuracy score =  0.11259079903147699\n",
            "-----------------------\n",
            "sentence number :  15\n",
            "BLEU score =  0.4392346096980261\n",
            "Accuracy score =  0.1228287841191067\n",
            "-----------------------\n",
            "sentence number :  16\n",
            "BLEU score =  0.4285682411832858\n",
            "Accuracy score =  0.11927710843373494\n",
            "-----------------------\n",
            "sentence number :  17\n",
            "BLEU score =  0.3754839699764456\n",
            "Accuracy score =  0.0856269113149847\n",
            "-----------------------\n",
            "sentence number :  18\n",
            "BLEU score =  0.4247238432112046\n",
            "Accuracy score =  0.09386733416770963\n",
            "-----------------------\n",
            "sentence number :  19\n",
            "BLEU score =  0.4266535176174841\n",
            "Accuracy score =  0.10532544378698225\n",
            "-----------------------\n",
            "sentence number :  20\n",
            "BLEU score =  0.4313089744562924\n",
            "Accuracy score =  0.10620525059665871\n",
            "-----------------------\n",
            "sentence number :  21\n",
            "BLEU score =  0.42627566911320164\n",
            "Accuracy score =  0.11438679245283019\n",
            "-----------------------\n",
            "sentence number :  22\n",
            "BLEU score =  0.42677983991633295\n",
            "Accuracy score =  0.08767772511848342\n",
            "-----------------------\n",
            "sentence number :  23\n",
            "BLEU score =  0.4271552293546905\n",
            "Accuracy score =  0.10110974106041924\n",
            "-----------------------\n",
            "sentence number :  24\n",
            "BLEU score =  0.4203219658448381\n",
            "Accuracy score =  0.1195840554592721\n",
            "-----------------------\n",
            "sentence number :  25\n",
            "BLEU score =  0.4216736598734381\n",
            "Accuracy score =  0.10889929742388758\n",
            "-----------------------\n",
            "sentence number :  26\n",
            "BLEU score =  0.4274142698523084\n",
            "Accuracy score =  0.10846245530393325\n",
            "-----------------------\n",
            "sentence number :  27\n",
            "BLEU score =  0.4315451964432697\n",
            "Accuracy score =  0.09595375722543352\n",
            "-----------------------\n",
            "sentence number :  28\n",
            "BLEU score =  0.41613913742004954\n",
            "Accuracy score =  0.10726643598615918\n",
            "-----------------------\n",
            "sentence number :  29\n",
            "BLEU score =  0.4182044074839973\n",
            "Accuracy score =  0.1354679802955665\n",
            "-----------------------\n",
            "sentence number :  30\n",
            "BLEU score =  0.42184950876134586\n",
            "Accuracy score =  0.1120584652862363\n",
            "-----------------------\n",
            "sentence number :  31\n",
            "BLEU score =  0.42649937722961534\n",
            "Accuracy score =  0.11397058823529412\n",
            "-----------------------\n",
            "sentence number :  32\n",
            "BLEU score =  0.4297785814074031\n",
            "Accuracy score =  0.11176470588235295\n",
            "-----------------------\n",
            "sentence number :  33\n",
            "BLEU score =  0.42108227398486997\n",
            "Accuracy score =  0.10399032648125756\n",
            "-----------------------\n",
            "sentence number :  34\n",
            "BLEU score =  0.42753292707725093\n",
            "Accuracy score =  0.10714285714285714\n",
            "-----------------------\n",
            "sentence number :  35\n",
            "BLEU score =  0.4279489557180948\n",
            "Accuracy score =  0.10062111801242236\n",
            "-----------------------\n",
            "sentence number :  36\n",
            "BLEU score =  0.42882680434233217\n",
            "Accuracy score =  0.09906291834002677\n",
            "-----------------------\n",
            "sentence number :  37\n",
            "BLEU score =  0.4224665119946087\n",
            "Accuracy score =  0.1217292377701934\n",
            "-----------------------\n",
            "sentence number :  38\n",
            "BLEU score =  0.42266700871090485\n",
            "Accuracy score =  0.12529550827423167\n",
            "-----------------------\n",
            "sentence number :  39\n",
            "BLEU score =  0.4286974252947707\n",
            "Accuracy score =  0.1037394451145959\n",
            "-----------------------\n",
            "sentence number :  40\n",
            "BLEU score =  0.43855604346738736\n",
            "Accuracy score =  0.11220715166461159\n",
            "-----------------------\n",
            "sentence number :  41\n",
            "BLEU score =  0.42766936651605614\n",
            "Accuracy score =  0.1087216248506571\n",
            "-----------------------\n",
            "sentence number :  42\n",
            "BLEU score =  0.41659636775319564\n",
            "Accuracy score =  0.13398058252427184\n",
            "-----------------------\n",
            "sentence number :  43\n",
            "BLEU score =  0.43576212700071526\n",
            "Accuracy score =  0.12980769230769232\n",
            "-----------------------\n",
            "sentence number :  44\n",
            "BLEU score =  0.4245615743774192\n",
            "Accuracy score =  0.12876052948255115\n",
            "-----------------------\n",
            "sentence number :  45\n",
            "BLEU score =  0.3779644730092272\n",
            "Accuracy score =  0.08843537414965986\n",
            "-----------------------\n",
            "sentence number :  46\n",
            "BLEU score =  0.42304254618367654\n",
            "Accuracy score =  0.10676156583629894\n",
            "-----------------------\n",
            "sentence number :  47\n",
            "BLEU score =  0.42291718165778264\n",
            "Accuracy score =  0.12559241706161137\n",
            "-----------------------\n",
            "sentence number :  48\n",
            "BLEU score =  0.4328670093639808\n",
            "Accuracy score =  0.10048426150121065\n",
            "-----------------------\n",
            "sentence number :  49\n",
            "BLEU score =  0.43734770368552467\n",
            "Accuracy score =  0.1073170731707317\n",
            "-----------------------\n",
            "sentence number :  50\n",
            "BLEU score =  0.4236721692178535\n",
            "Accuracy score =  0.11217183770883055\n",
            "-----------------------\n",
            "sentence number :  51\n",
            "BLEU score =  0.4277972007454008\n",
            "Accuracy score =  0.09928229665071771\n",
            "-----------------------\n",
            "sentence number :  52\n",
            "BLEU score =  0.4264014327112209\n",
            "Accuracy score =  0.10743801652892562\n",
            "-----------------------\n",
            "sentence number :  53\n",
            "BLEU score =  0.43145615378992996\n",
            "Accuracy score =  0.1150990099009901\n",
            "-----------------------\n",
            "sentence number :  54\n",
            "BLEU score =  0.43842966659040056\n",
            "Accuracy score =  0.12514898688915377\n",
            "-----------------------\n",
            "sentence number :  55\n",
            "BLEU score =  0.42379865741502165\n",
            "Accuracy score =  0.10253456221198157\n",
            "-----------------------\n",
            "sentence number :  56\n",
            "BLEU score =  0.4245342089079177\n",
            "Accuracy score =  0.09280742459396751\n",
            "-----------------------\n",
            "sentence number :  57\n",
            "BLEU score =  0.4275417230556341\n",
            "Accuracy score =  0.09665871121718377\n",
            "-----------------------\n",
            "sentence number :  58\n",
            "BLEU score =  0.42254219930450104\n",
            "Accuracy score =  0.11216056670602124\n",
            "-----------------------\n",
            "sentence number :  59\n",
            "BLEU score =  0.42615009076134913\n",
            "Accuracy score =  0.0895170789163722\n",
            "-----------------------\n",
            "sentence number :  60\n",
            "BLEU score =  0.4215929872023278\n",
            "Accuracy score =  0.10935601458080195\n",
            "-----------------------\n",
            "sentence number :  61\n",
            "BLEU score =  0.430394752998613\n",
            "Accuracy score =  0.11782945736434108\n",
            "-----------------------\n",
            "sentence number :  62\n",
            "BLEU score =  0.42728700639623407\n",
            "Accuracy score =  0.12298850574712644\n",
            "<<------------final report----------->>\n",
            "number of test set =  62\n",
            "mean BLEU score =  0.4264708896520507\n",
            "mean Accuracy score =  0.10963404692435133\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}